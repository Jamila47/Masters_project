{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to do methylation calling with tombo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a re-run of the notebook for revisions. There are some adjustments based on adjusted input infrastructure. Rewind with git for older version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####One OUT_DIR per treatment. This should be one for germinated spores and one for infected leaves\n",
    "IN_DIR = os.path.abspath('../../data/genomic_data/infected_leaves/workspace_fast5/basecalled/workspace/singleFast5')\n",
    "#####One OUT_DIR per treatment. This should be one for germinated spores and one for infected leaves\n",
    "OUT_DIR = os.path.abspath('../../analyses/methylation_calling/infected_leaves')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_genome = os.path.abspath('../../data/genomic_resources/chr_A_B_unassigned.fasta')\n",
    "n_threads = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 checking the input"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mappingid_fns = []\n",
    "for dir_ in os.listdir(INITIAL_MAPPED_BASEDIR):\n",
    "    dir_ = os.path.join(INITIAL_MAPPED_BASEDIR, dir_) \n",
    "    if os.path.isdir(dir_):\n",
    "        mappingid_fn = [os.path.join(dir_, x) for x in os.listdir(dir_) if x.endswith('.mappedids.txt') ][0]\n",
    "        mappingid_fns.append(mappingid_fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nummapped_reads = 0\n",
    "for mappingid_fn in mappingid_fns:\n",
    "    with open(mappingid_fn, mode = 'r') as fh:\n",
    "        for line in fh:\n",
    "            nummapped_reads += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#This checks if the number of mapped reads is consistent with the number of single fast5s\n",
    "len([x for x in os.listdir(IN_DIR) if x.endswith('.fast5')]) == nummapped_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 tombo methylation calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tombo = '/home/jamila/anaconda3/bin/tombo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory\n",
    "os.chdir(OUT_DIR)\n",
    "basename = os.path.basename(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_resquiggle\n",
    "%time\n",
    "!{tombo} resquiggle {IN_DIR} {ref_genome} --processes {n_threads} --num-most-common-error 5 --dna --ignore-read-locks --overwrite  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_resquiggle.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_resquiggle.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_detect_modifications\n",
    "%time\n",
    "!{tombo} detect_modifications alternative_model --fast5-basedirs {IN_DIR} --statistics-file-basename {basename} --alternate-bases 5mC 6mA --processes {n_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 us, sys: 0 ns, total: 3 us\n",
      "Wall time: 16 us\n",
      "[23:58:04] Parsing Tombo index file(s).\n",
      "[23:58:16] Performing alternative model testing.\n",
      "[23:58:17] Performing specific alternate base(s) testing.\n",
      "[23:58:17] Calculating read coverage regions.\n",
      "[23:58:17] Calculating read coverage.\n",
      "[23:58:27] Performing modified base detection across genomic regions.\n",
      " 17%|██████▏                             | 6098/35430 [18:48<1:30:27,  5.40it/s]OMP: Error #34: System unable to allocate necessary resources for OMP thread:\n",
      "OMP: System error #11: Resource temporarily unavailable\n",
      "OMP: Hint Try decreasing the value of OMP_NUM_THREADS.\n",
      " 39%|█████████████▋                     | 13908/35430 [43:03<1:06:37,  5.38it/s]OMP: Error #34: System unable to allocate necessary resources for OMP thread:\n",
      "OMP: System error #11: Resource temporarily unavailable\n",
      "OMP: Hint Try decreasing the value of OMP_NUM_THREADS.\n",
      "100%|██████████████████████████████████▉| 35428/35430 [1:54:08<00:00,  5.17it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_detect_modifications.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_detect_modifications.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_most_significant_5mC\n",
    "%time\n",
    "!{tombo} plot most_significant --fast5-basedirs {IN_DIR} --statistics-filename {basename}.5mC.tombo.stats  --plot-standard-model --plot-alternate-model 5mC --pdf-filename {basename}.most_significant_5mC_sites.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3 us, total: 3 us\n",
      "Wall time: 10.7 us\n",
      "[01:52:40] Loading statistics from file.\n",
      "[01:52:45] Parsing Tombo index file(s).\n",
      "[01:52:58] Loading default canonical ***** DNA ***** model.\n",
      "[01:52:59] Preparing plot data.\n",
      "[01:53:02] Plotting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_most_significant_5mC.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_most_significant_5mC.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_most_significant_6mA\n",
    "%time\n",
    "!{tombo} plot most_significant --fast5-basedirs {IN_DIR} --statistics-filename {basename}.6mA.tombo.stats  --plot-standard-model --plot-alternate-model 6mA --pdf-filename {basename}.most_significant_6mA_sites.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3 us, total: 3 us\n",
      "Wall time: 5.96 us\n",
      "[01:53:08] Loading statistics from file.\n",
      "[01:53:14] Parsing Tombo index file(s).\n",
      "[01:53:27] Loading default canonical ***** DNA ***** model.\n",
      "[01:53:27] Preparing plot data.\n",
      "[01:53:30] Plotting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_most_significant_6mA.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_most_significant_6mA.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_5mC_wigfile\n",
    "%time\n",
    "!{tombo} text_output browser_files --statistics-filename {basename}.5mC.tombo.stats --file-type dampened_fraction --browser-file-basename {basename}.5mC\n",
    "##produce wig files with estimated fraction if modified reads at each valid reference site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 us, sys: 2 us, total: 3 us\n",
      "Wall time: 5.48 us\n",
      "[01:53:35] Loading statistics from file.\n",
      "[01:53:40] Parsing and outputting statistics wiggles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_5mC_wigfile.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_5mC_wigfile.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out_6mA_wig\n",
    "%time\n",
    "!{tombo} text_output browser_files --statistics-filename {basename}.6mA.tombo.stats --file-type dampened_fraction --browser-file-basename {basename}.6mA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 us, sys: 0 ns, total: 2 us\n",
      "Wall time: 16 us\n",
      "[11:26:50] Loading statistics from file.\n",
      "[11:26:55] Parsing and outputting statistics wiggles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print stdout\n",
    "print(cap_out_6mA_wig.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###print stderr\n",
    "print(cap_out_6mA_wig.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tombo text_output [-h] {browser_files,signif_sequence_context} ...\n",
      "tombo text_output: error: argument action_command: invalid choice: 'browser_file' (choose from 'browser_files', 'signif_sequence_context')\n"
     ]
    }
   ],
   "source": [
    "###to produce successfully processed reads coverage file for reference\n",
    "!{tombo} text_output browser_file --fast5-basedirs {IN_DIR} --file-types coverage --browser-file-basename {basename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:04] Parsing Tombo index file(s).\n",
      "[11:32:17] Getting and writing  coverage bedgraphs.\n",
      "[11:32:17] Calculating read coverage regions.\n",
      "[11:32:17] Calculating read coverage.\n"
     ]
    }
   ],
   "source": [
    "###to produce successfully processed reads coverage file for reference\n",
    "!{tombo} text_output browser_files --fast5-basedirs {IN_DIR} --file-types coverage --browser-file-basename {basename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code not used here anymore as we already have single fast5s and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###first check if we have the right amount of fastq entries in our file\n",
    "int(fastq_entries[0]) == single_fast5_count\n",
    "###You want this to be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Now check on if ids match up\n",
    "fastqids_fn = fastq_all_fn.replace('.fastq', '.fastqids.txt')\n",
    "!cat {fastq_all_fn} | grep 'sampleid'|  cut -d ' ' -f 1 | sed 's/@//g' > {fastqids_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Read in ids as set\n",
    "fastq_ids = []\n",
    "with open(fastqids_fn) as fh:\n",
    "    for line in fh:\n",
    "        fastq_ids.append(line.strip('\\n'))\n",
    "fastq_ids = set(fastq_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_count = 0\n",
    "for directory in os.listdir(FAST5singleIN_DIR):\n",
    "    directory = os.path.join(FAST5singleIN_DIR, directory)\n",
    "    if os.path.isdir(directory):\n",
    "        fast5s = [fn for fn in os.listdir(directory) if fn.endswith('.fast5')]\n",
    "        for fast5_file in fast5s: \n",
    "            if fast5_file.replace('.fast5', '') in fastq_ids:\n",
    "                match_count = match_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####This needs to be true\n",
    "match_count == int(fastq_entries[0]) == single_fast5_count\n",
    "####This needs to be true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If above is false go to section 3 and execute this before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 mapping the reads and pulling out the mapped fast5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_fn = os.path.join(BAM_DIR, os.path.basename(fastq_all_fn).replace('.fastq', '.sorted.bam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!minimap2 -t 15 -ax map-ont {minimap_index} {fastq_all_fn} | samtools sort -@ 15 -o {bam_fn} -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is only here because the mapping was done on the command line and not in here\n",
    "#if mapping is done in here don't execute this cell\n",
    "bam_fn = '../../analyses/mapping/infected_leaves/infected_leaves_1/infected_leaves_1.sorted.bam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##generated the mapped read ID list\n",
    "mappedids_fn = bam_fn.replace('.bam', '.mappedids.txt')\n",
    "!samtools  view -F 4  {bam_fn} | cut -f 1 | sort | uniq > {mappedids_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mapped ids as a set\n",
    "mapped_reads = []\n",
    "with open(mappedids_fn) as fh:\n",
    "    for line in fh:\n",
    "        mapped_reads.append(line.rstrip())\n",
    "mapped_reads = set(mapped_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mapped_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move fast5s you want from tmp to out dir\n",
    "match_count = 0\n",
    "for directory in os.listdir(FAST5singleIN_DIR):\n",
    "    directory = os.path.join(FAST5singleIN_DIR, directory)\n",
    "    #check if path is directory\n",
    "    if os.path.isdir(directory):\n",
    "        #get all fastq files\n",
    "        fast5s = [fn for fn in os.listdir(directory) if fn.endswith('.fast5')]\n",
    "        for fast5_file in fast5s:\n",
    "            if fast5_file.replace('.fast5', '') in mapped_reads:\n",
    "                match_count = match_count + 1\n",
    "                #move the files by renaming absolute path\n",
    "                old_fn = os.path.join(directory, fast5_file)\n",
    "                new_fn = os.path.join(OUT_DIR, fast5_file)\n",
    "                os.replace(old_fn, new_fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This should be true\n",
    "len(mapped_reads) == match_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are useful code snippets we leave for now but won't execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 Regenerating fastqs if they don't add up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run only if the tests above do fail\n",
    "%run -i infected_leaves_2_fast5_to_fastq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all fastqs\n",
    "all_fastq_fn = os.path.join(FAST5singleIN_DIR,  '%s.fastq' % os.path.basename(FAST5singleIN_DIR))\n",
    "with open(all_fastq_fn, mode='w') as all_fastq_fh:\n",
    "    for dir_ in dirs:\n",
    "        fn = os.path.join(os.path.join(dir_), os.path.basename(dir_) + '.fastq')\n",
    "        #print(fn)\n",
    "        with open(fn, mode = 'r') as fh:\n",
    "            for line in fh:\n",
    "                line = line.rstrip()\n",
    "                print(line, file=all_fastq_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_entries = !cat {all_fastq_fn} | grep 'sampleid' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(fastq_entries[0]) == single_fast5_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fastq_fn = os.path.join(FAST5singleIN_DIR,  '%s.fastq' % os.path.basename(FAST5singleIN_DIR))\n",
    "fastqids_fn = all_fastq_fn.replace('.fastq', '.fastqids.txt')\n",
    "!cat {all_fastq_fn} | grep 'sampleid'|  cut -d ' ' -f 1 | sed 's/@//g' > {fastqids_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_reads = []\n",
    "with open(fastqids_fn) as fh:\n",
    "    for line in fh:\n",
    "        fastq_reads.append(line.strip('\\n'))\n",
    "fastq_reads = set(fastq_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fastq_reads) == single_fast5_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "TMPOUT_DIR = FAST5singleIN_DIR\n",
    "for directory in os.listdir(TMPOUT_DIR):\n",
    "    directory = os.path.join(TMPOUT_DIR, directory)\n",
    "    #check if path is directory\n",
    "    if os.path.isdir(directory):\n",
    "        #print(directory)\n",
    "        fast5s = [fn for fn in os.listdir(directory) if fn.endswith('.fast5')]\n",
    "        #missing = set([x.replace('.fast5', '') for x in fast5s]) - fastq_reads\n",
    "        #print(len(missing))\n",
    "        for fast5_file in fast5s:\n",
    "            \n",
    "            if fast5_file.replace('.fast5', '') in fastq_reads:\n",
    "                count = count + 1\n",
    "                #move the files by renaming absolute path\n",
    "                #old_fn = os.path.join(directory, fast5_file)\n",
    "                #new_fn = os.path.join(OUT_DIR, fast5_file)\n",
    "                #os.replace(old_fn, new_fn)\n",
    "        #count = count + len(fast5s)\n",
    "        #print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count == single_fast5_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
